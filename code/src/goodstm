#include "stm-coloring.h"
#include <algorithm>
#include <string.h>
#include <mutex>
#include <iostream>
#include <memory>
#include <queue>
#include <vector>
#include <omp.h>
#include <unordered_set>
#include <atomic>
#include <unordered_map>
#include <random>

// Thread-local storage for color arrays
thread_local bool* forbidden_colors = nullptr;

// Initialize thread-local storage
void initThreadLocalStorage() {
    if (forbidden_colors == nullptr) {
        forbidden_colors = new bool[MAX_COLORS]();
    } else {
        memset(forbidden_colors, 0, MAX_COLORS * sizeof(bool));
    }
}

// Cleanup thread-local storage
void cleanupThreadLocalStorage() {
    if (forbidden_colors != nullptr) {
        delete[] forbidden_colors;
        forbidden_colors = nullptr;
    }
}

// Thread-local statistics tracking
struct ThreadColorStats {
    int max_color;
    int conflicts;
    ThreadColorStats() : max_color(0), conflicts(0) {}
};

// Constructor implementations for derived classes
LibITMColorGraph::LibITMColorGraph(int iterations, bool try_bipartite)
    : STMColorGraph(STMType::Libitm, iterations, try_bipartite) {
}

TL2ColorGraph::TL2ColorGraph(int iterations, bool try_bipartite)
    : STMColorGraph(STMType::TL2, iterations, try_bipartite) {
}

// Constructor
STMColorGraph::STMColorGraph(STMType type, int iterations, bool try_bipartite) 
    : stm_type(type),
      max_iterations(iterations), 
      detect_bipartite(try_bipartite),
      global_max_color(0) {
    
    initThreadLocalStorage();
    
    const char* type_names[] = {"LibITM", "TL2", "Hybrid", "TMGraph"};
    std::cout << "STM Graph Coloring (" << type_names[static_cast<int>(type)] << ")\n";
    std::cout << "Max iterations: " << max_iterations << "\n";
    std::cout << "Bipartite detection: " << (detect_bipartite ? "enabled" : "disabled") << "\n";
}

// Destructor
STMColorGraph::~STMColorGraph() {
    // Cleanup is handled via atexit
}

// Graph building implementation
void STMColorGraph::buildGraph(
    std::vector<graphNode> &nodes,
    std::vector<std::pair<graphNode, graphNode>> &pairs,
    std::unordered_map<graphNode, std::vector<graphNode>> &graph) {
    
    std::cout << "Building graph..." << std::endl;
    graph.clear();
    
    // Initialize graph with all nodes
    for (auto node : nodes) {
        graph[node];
    }
    
    // Add edges
    for (auto& edge : pairs) {
        if (edge.first < 0 || edge.second < 0 || edge.first == edge.second) {
            continue;
        }
        
        auto& neighbors = graph[edge.first];
        if (std::find(neighbors.begin(), neighbors.end(), edge.second) == neighbors.end()) {
            graph[edge.first].push_back(edge.second);
            graph[edge.second].push_back(edge.first);
        }
    }
    
    // Print statistics
    size_t total_edges = 0;
    for (const auto& adj_list : graph) {
        total_edges += adj_list.second.size();
    }
    std::cout << "Graph built: " << graph.size() << " nodes, " 
              << (total_edges / 2) << " edges" << std::endl;
}

// Helper function to check if a node is colored correctly
bool isNodeColoredCorrectly(size_t node_idx, const std::vector<color>& node_colors, 
                          const std::vector<bool>& colored,
                          const std::vector<std::vector<size_t>>& neighbor_indices) {
    if (!colored[node_idx]) return false;
    
    for (size_t nb_idx : neighbor_indices[node_idx]) {
        if (colored[nb_idx] && node_colors[nb_idx] == node_colors[node_idx]) {
            return false;
        }
    }
    return true;
}

// Function to find best color for a node - fixed to be thread-safe
// Modified findBestColor function to ensure we're not returning color 0 for all nodes
color findBestColor(size_t node_idx, const std::vector<color>& node_colors, 
    const std::vector<bool>& colored,
    const std::vector<std::vector<size_t>>& neighbor_indices,
    bool allow_new_colors = false, color current_max = 0) {

// Make sure thread-local storage is initialized
if (forbidden_colors == nullptr) {
initThreadLocalStorage();
}

// Clear forbidden colors with bounds checking
if (forbidden_colors != nullptr) {
memset(forbidden_colors, 0, MAX_COLORS * sizeof(bool));
} else {
// If thread-local storage failed, use a local array as fallback
bool local_forbidden[MAX_COLORS] = {0};
forbidden_colors = local_forbidden;
}

// Mark forbidden colors from neighbors with bounds checking
for (size_t i = 0; i < neighbor_indices[node_idx].size(); i++) {
size_t nb_idx = neighbor_indices[node_idx][i];

// Bounds check for neighbor index
if (nb_idx >= colored.size()) continue;

if (colored[nb_idx]) {
color c = node_colors[nb_idx];
if (c >= 0 && c < MAX_COLORS) {
  forbidden_colors[c] = true;
}
}
}

// Find first available color
color selected = 0;
while (selected < MAX_COLORS && forbidden_colors[selected]) {
selected++;
}

// If no color found and new colors allowed, use beyond max
if (selected >= MAX_COLORS && allow_new_colors) {
selected = current_max + 1;
} else if (selected >= MAX_COLORS) {
// Fallback: choose color with least conflicts
std::vector<int> conflict_counts(MAX_COLORS, 0);

for (size_t i = 0; i < neighbor_indices[node_idx].size(); i++) {
size_t nb_idx = neighbor_indices[node_idx][i];

// Bounds check
if (nb_idx >= colored.size()) continue;

if (colored[nb_idx]) {
  color c = node_colors[nb_idx];
  if (c >= 0 && c < MAX_COLORS) {
      conflict_counts[c]++;
  }
}
}

// Find color with minimum conflicts
int min_conflicts = std::numeric_limits<int>::max();
for (color c = 0; c < MAX_COLORS; c++) {
if (conflict_counts[c] < min_conflicts) {
  min_conflicts = conflict_counts[c];
  selected = c;
}
}
}

return selected;
}

// Optimized workload distribution function
void createOptimizedWorkDistribution(
    std::vector<size_t>& partitioned_nodes,
    const std::vector<std::vector<size_t>>& neighbor_indices,
    size_t seq_nodes, size_t node_count, int num_partitions) {
    
    partitioned_nodes.clear();
    partitioned_nodes.reserve(node_count - seq_nodes);
    
    // Create node clusters to reduce transaction conflicts
    std::vector<std::vector<size_t>> clusters;
    std::unordered_set<size_t> visited;
    
    // Seed for random generator
    std::random_device rd;
    std::mt19937 gen(rd());
    
    // Create initial set of seed nodes distributed across the graph
    std::vector<size_t> seed_nodes;
    size_t step = (node_count - seq_nodes) / std::min(static_cast<size_t>(100), node_count - seq_nodes);
    if (step < 1) step = 1;
    
    for (size_t i = seq_nodes; i < node_count; i += step) {
        seed_nodes.push_back(i);
    }
    
    // Shuffle seed nodes for better distribution
    std::shuffle(seed_nodes.begin(), seed_nodes.end(), gen);
    
    // Process seed nodes to form clusters
    for (size_t seed : seed_nodes) {
        if (visited.find(seed) != visited.end()) continue;
        
        // Create a new cluster
        std::vector<size_t> cluster;
        std::queue<size_t> queue;
        queue.push(seed);
        visited.insert(seed);
        
        // BFS to find related nodes, limiting cluster size
        const size_t max_cluster_size = 250;
        while (!queue.empty() && cluster.size() < max_cluster_size) {
            size_t current = queue.front();
            queue.pop();
            cluster.push_back(current);
            
            // Add unvisited neighbors, prioritizing those with similar degree
            // This helps keep related nodes together, reducing conflicts
            std::vector<std::pair<size_t, size_t>> neighbors_with_degree;
            for (size_t nb : neighbor_indices[current]) {
                if (nb >= seq_nodes && visited.find(nb) == visited.end()) {
                    size_t degree_diff = std::abs(
                        static_cast<int>(neighbor_indices[nb].size()) - 
                        static_cast<int>(neighbor_indices[current].size())
                    );
                    neighbors_with_degree.push_back({nb, degree_diff});
                }
            }
            
            // Sort by degree similarity
            std::sort(neighbors_with_degree.begin(), neighbors_with_degree.end(),
                [](const auto& a, const auto& b) {
                    return a.second < b.second;
                });
            
            // Add closest neighbors first, with limit
            const int max_neighbors_per_node = 8;
            int added = 0;
            for (const auto& [nb, _] : neighbors_with_degree) {
                if (added >= max_neighbors_per_node) break;
                queue.push(nb);
                visited.insert(nb);
                added++;
            }
        }
        
        // Sort cluster by node degree for better coloring
        std::sort(cluster.begin(), cluster.end(),
            [&neighbor_indices](size_t a, size_t b) {
                return neighbor_indices[a].size() > neighbor_indices[b].size();
            });
        
        if (!cluster.empty()) {
            clusters.push_back(cluster);
        }
    }
    
    // Add any remaining nodes to their own small clusters
    for (size_t i = seq_nodes; i < node_count; i++) {
        if (visited.find(i) == visited.end()) {
            std::vector<size_t> singleton = {i};
            clusters.push_back(singleton);
            visited.insert(i);
        }
    }
    
    // Sort clusters by size (largest first) for better load balancing
    std::sort(clusters.begin(), clusters.end(),
        [](const std::vector<size_t>& a, const std::vector<size_t>& b) {
            return a.size() > b.size();
        });
    
    // Distribute clusters to partitions in a way that balances load
    // Use a greedy bin-packing approach
    std::vector<std::vector<size_t>> balanced_partitions(num_partitions);
    std::vector<size_t> partition_sizes(num_partitions, 0);
    
    for (const auto& cluster : clusters) {
        // Find partition with minimum current load
        int target_partition = 0;
        size_t min_size = partition_sizes[0];
        
        for (int p = 1; p < num_partitions; p++) {
            if (partition_sizes[p] < min_size) {
                min_size = partition_sizes[p];
                target_partition = p;
            }
        }
        
        // Add cluster to target partition
        balanced_partitions[target_partition].insert(
            balanced_partitions[target_partition].end(),
            cluster.begin(), cluster.end()
        );
        partition_sizes[target_partition] += cluster.size();
    }
    
    // Create flattened node list with optimal ordering
    // Interleave partitions to distribute high-degree nodes
    size_t max_partition_size = 0;
    for (const auto& partition : balanced_partitions) {
        max_partition_size = std::max(max_partition_size, partition.size());
    }
    
    for (size_t i = 0; i < max_partition_size; i++) {
        for (int p = 0; p < num_partitions; p++) {
            if (i < balanced_partitions[p].size()) {
                partitioned_nodes.push_back(balanced_partitions[p][i]);
            }
        }
    }
}

// Adaptive thread configuration based on graph characteristics
void configureThreads(size_t node_count, size_t edge_count, double avg_degree, 
                     int& active_threads, int& chunk_size) {
    int max_threads = omp_get_max_threads();
    
    // Determine optimal thread count based on graph characteristics
    if (node_count < 5000) {
        active_threads = std::min(max_threads, 4);
    } else if (node_count < 50000) {
        if (avg_degree > 100) {
            active_threads = std::min(max_threads, 8);
        } else if (avg_degree > 20) {
            active_threads = std::min(max_threads, 16);
        } else {
            active_threads = std::min(max_threads, 32);
        }
    } else {
        if (avg_degree > 100) {
            active_threads = std::min(max_threads, 16);
        } else if (avg_degree > 20) {
            active_threads = std::min(max_threads, 32);
        } else {
            active_threads = max_threads;
        }
    }
    
    // Determine optimal chunk size
    // Dense graphs need smaller chunks to reduce conflicts
    if (avg_degree > 100) {
        chunk_size = 32;
    } else if (avg_degree > 50) {
        chunk_size = 64;
    } else if (avg_degree > 20) {
        chunk_size = 128;
    } else {
        chunk_size = 256;
    }
    
    // Scale chunk size based on thread count
    chunk_size = std::max(16, chunk_size / ((active_threads > 8) ? (active_threads / 8) : 1));
    
    // Print configuration
    if (active_threads < max_threads) {
        std::cout << "Optimized configuration: " << active_threads << " threads, chunk size " 
                 << chunk_size << " for avg degree " << avg_degree << std::endl;
        omp_set_num_threads(active_threads);
    }
}

// Speculative coloring for a batch of nodes
void speculativeColoring(const std::vector<size_t>& nodes, 
                       std::vector<color>& node_colors,
                       std::vector<bool>& colored,
                       const std::vector<std::vector<size_t>>& neighbor_indices,
                       int& global_max_color) {
    
    const size_t batch_size = std::min(static_cast<size_t>(256), nodes.size());
    std::vector<size_t> batch_nodes(nodes.begin(), nodes.begin() + batch_size);
    
    // Phase 1: Make speculative color assignments
    std::vector<color> speculative_colors(batch_size);
    
    #pragma omp parallel for
    for (size_t i = 0; i < batch_size; i++) {
        size_t node_idx = batch_nodes[i];
        
        // Skip already colored nodes
        if (colored[node_idx]) {
            speculative_colors[i] = -1;
            continue;
        }
        
        // Determine color speculatively
        speculative_colors[i] = findBestColor(node_idx, node_colors, colored, neighbor_indices);
    }
    
    // Phase 2: Validation & Commit
    #pragma omp parallel
    {
        ThreadColorStats local_stats;
        
        #pragma omp for
        for (size_t i = 0; i < batch_size; i++) {
            size_t node_idx = batch_nodes[i];
            color selected = speculative_colors[i];
            
            // Skip already colored nodes or invalid speculative colors
            if (colored[node_idx] || selected == -1) continue;
            
            // Check if speculative coloring is still valid
            bool still_valid = true;
            for (size_t nb_idx : neighbor_indices[node_idx]) {
                if (colored[nb_idx] && node_colors[nb_idx] == selected) {
                    still_valid = false;
                    break;
                }
            }
            
            if (still_valid) {
                // Fast path: no conflicts, can commit without STM
                node_colors[node_idx] = selected;
                colored[node_idx] = true;
                
                // Update max color locally
                if (selected > local_stats.max_color) {
                    local_stats.max_color = selected;
                }
            } else {
                // Slow path: needs transaction due to potential conflict
                // Compute color outside transaction first
                color recomputed_color = findBestColor(node_idx, node_colors, colored, 
                                                   neighbor_indices, false, global_max_color);
                
                bool success = false;
                
                // Try to color with transaction - just apply the pre-computed color
                __transaction_atomic {
                    if (!colored[node_idx]) {
                        node_colors[node_idx] = recomputed_color;
                        colored[node_idx] = true;
                        success = true;
                    }
                }
                
                // Update max color if successful
                if (success && recomputed_color > local_stats.max_color) {
                    local_stats.max_color = recomputed_color;
                }
            }
        }
        
        // Update global max color
        if (local_stats.max_color > 0) {
            #pragma omp critical
            {
                if (local_stats.max_color > global_max_color) {
                    global_max_color = local_stats.max_color;
                }
            }
        }
    }
}

// Advanced conflict resolution for stubborn nodes
void advancedConflictResolution(std::vector<size_t>& conflict_nodes,
                              std::vector<color>& node_colors,
                              std::vector<bool>& colored,
                              const std::vector<std::vector<size_t>>& neighbor_indices,
                              int& global_max_color) {
    
    if (conflict_nodes.empty()) return;
    
    // Sort conflicts by degree for better resolution
    std::sort(conflict_nodes.begin(), conflict_nodes.end(),
        [&neighbor_indices](size_t a, size_t b) {
            return neighbor_indices[a].size() > neighbor_indices[b].size();
        });
    
    // Identify clusters of conflicting nodes
    std::unordered_map<size_t, std::vector<size_t>> conflict_clusters;
    std::unordered_set<size_t> processed;
    
    for (size_t node : conflict_nodes) {
        if (processed.find(node) != processed.end()) continue;
        
        // Find all conflicts in this cluster
        std::vector<size_t> cluster = {node};
        std::queue<size_t> queue;
        queue.push(node);
        processed.insert(node);
        
        while (!queue.empty()) {
            size_t current = queue.front();
            queue.pop();
            
            for (size_t nb : neighbor_indices[current]) {
                // Add neighboring conflict nodes to cluster
                if (std::find(conflict_nodes.begin(), conflict_nodes.end(), nb) != conflict_nodes.end() &&
                    processed.find(nb) == processed.end()) {
                    cluster.push_back(nb);
                    queue.push(nb);
                    processed.insert(nb);
                }
            }
        }
        
        if (cluster.size() > 1) {
            conflict_clusters[node] = cluster;
        }
    }
    
    // Process conflict clusters first
    for (const auto& [root, cluster] : conflict_clusters) {
        // For each cluster, assign incrementing colors to ensure no conflicts
        color cluster_base_color = global_max_color + 1;
        
        #pragma omp parallel for
        for (size_t i = 0; i < cluster.size(); i++) {
            size_t node_idx = cluster[i];
            color new_color = cluster_base_color + i;
            
            __transaction_atomic {
                node_colors[node_idx] = new_color;
                colored[node_idx] = true;
            }
        }
        
        // Update global max color
        color cluster_max = cluster_base_color + cluster.size() - 1;
        #pragma omp critical
        {
            if (cluster_max > global_max_color) {
                global_max_color = cluster_max;
            }
        }
        
        // Remove processed nodes from conflict list
        for (size_t node : cluster) {
            auto it = std::find(conflict_nodes.begin(), conflict_nodes.end(), node);
            if (it != conflict_nodes.end()) {
                *it = conflict_nodes.back();
                conflict_nodes.pop_back();
            }
        }
    }
    
    // Handle remaining individual conflicts with optimistic approach
    if (!conflict_nodes.empty()) {
        const int batch_size = std::min(static_cast<int>(conflict_nodes.size()), 64);
        
        #pragma omp parallel
        {
            ThreadColorStats local_stats;
            
            #pragma omp for schedule(dynamic, 1)
            for (int i = 0; i < static_cast<int>(conflict_nodes.size()); i += batch_size) {
                int end = std::min(i + batch_size, static_cast<int>(conflict_nodes.size()));
                
                for (int j = i; j < end; j++) {
                    size_t node_idx = conflict_nodes[j];
                    
                    // Try optimistic coloring first
                    color selected = findBestColor(node_idx, node_colors, colored, 
                                               neighbor_indices, true, global_max_color);
                    
                    // Use transaction to ensure correctness
                    bool success = false;
                    __transaction_atomic {
                        node_colors[node_idx] = selected;
                        colored[node_idx] = true;
                        success = true;
                    }
                    
                    // Update max color if needed
                    if (success && selected > local_stats.max_color) {
                        local_stats.max_color = selected;
                    }
                }
            }
            
            // Update global max color
            if (local_stats.max_color > 0) {
                #pragma omp critical
                {
                    if (local_stats.max_color > global_max_color) {
                        global_max_color = local_stats.max_color;
                    }
                }
            }
        }
    }
}

// Main coloring algorithm with optimizations
// Optimized STM graph coloring for dense graphs - guaranteed correct results
void STMColorGraph::colorGraph(
    std::unordered_map<graphNode, std::vector<graphNode>> &graph,
    std::unordered_map<graphNode, color> &colors) {
    
    // Start timer for performance measurement
    double start_time = omp_get_wtime();
    
    std::cout << "Starting highly optimized STM coloring..." << std::endl;
    colors.clear();

    if (graph.empty()) {
        std::cout << "Empty graph, nothing to color." << std::endl;
        return;
    }

    // Phase 1: Graph Initialization - More efficient preprocessing
    const size_t node_count = graph.size();
    std::vector<graphNode> ordered_nodes;
    ordered_nodes.reserve(node_count);

    // Pre-calculate degrees to avoid repeated map lookups
    std::vector<std::pair<graphNode, size_t>> nodes_with_degrees;
    nodes_with_degrees.reserve(node_count);
    
    // Find maximum node ID for direct indexing
    graphNode max_node_id = 0;
    for (const auto& entry : graph) {
        nodes_with_degrees.emplace_back(entry.first, entry.second.size());
        max_node_id = std::max(max_node_id, entry.first);
    }
    
    // Sort by degree (parallel sort for large graphs)
    if (node_count > 10000) {
        #pragma omp parallel
        {
            #pragma omp single
            std::sort(nodes_with_degrees.begin(), nodes_with_degrees.end(),
                [](const auto& a, const auto& b) {
                    return a.second > b.second;  // Descending by degree
                });
        }
    } else {
        std::sort(nodes_with_degrees.begin(), nodes_with_degrees.end(),
            [](const auto& a, const auto& b) {
                return a.second > b.second;  // Descending by degree
            });
    }
    
    // Extract sorted nodes
    for (const auto& node_degree : nodes_with_degrees) {
        ordered_nodes.push_back(node_degree.first);
    }
    
    // Direct node-to-index mapping if possible
    std::vector<int> node_to_index_vec;
    bool use_direct_indexing = (max_node_id < 10 * node_count);  // Only use if dense node IDs
    
    if (use_direct_indexing) {
        node_to_index_vec.resize(max_node_id + 1, -1);
        #pragma omp parallel for
        for (size_t i = 0; i < ordered_nodes.size(); i++) {
            node_to_index_vec[ordered_nodes[i]] = i;
        }
    }
    
    // Use hash map as fallback
    std::unordered_map<graphNode, size_t> node_to_index;
    if (!use_direct_indexing) {
        node_to_index.reserve(node_count);
        for (size_t i = 0; i < ordered_nodes.size(); i++) {
            node_to_index[ordered_nodes[i]] = i;
        }
    }
    
    // Create flat adjacency structure for better cache locality
    std::vector<size_t> all_neighbors;
    std::vector<size_t> neighbor_offsets(node_count + 1, 0);
    
    // Calculate total neighbors and offsets
    size_t total_neighbors = 0;
    for (size_t i = 0; i < ordered_nodes.size(); i++) {
        neighbor_offsets[i] = total_neighbors;
        total_neighbors += graph.at(ordered_nodes[i]).size();
    }
    neighbor_offsets[node_count] = total_neighbors;
    all_neighbors.resize(total_neighbors);
    
    // Populate flat adjacency structure
    #pragma omp parallel for
    for (size_t i = 0; i < ordered_nodes.size(); i++) {
        auto& neighbors = graph.at(ordered_nodes[i]);
        size_t offset = neighbor_offsets[i];
        for (size_t j = 0; j < neighbors.size(); j++) {
            graphNode neighbor = neighbors[j];
            size_t neighbor_idx;
            
            if (use_direct_indexing) {
                if (neighbor <= max_node_id) {
                    neighbor_idx = node_to_index_vec[neighbor];
                } else {
                    neighbor_idx = SIZE_MAX;  // Invalid index
                }
            } else {
                auto it = node_to_index.find(neighbor);
                neighbor_idx = (it != node_to_index.end()) ? it->second : SIZE_MAX;
            }
            
            if (neighbor_idx != SIZE_MAX) {
                all_neighbors[offset + j] = neighbor_idx;
            }
        }
    }
    
    // Aligned memory allocation for better SIMD performance
    size_t padded_size = (node_count + 63) & ~63;  // Round up to multiple of 64 for cache alignment
    
    // Allocate aligned memory
    color* aligned_colors;
    char* aligned_colored;
    
    #ifdef _MSC_VER
        aligned_colors = (color*)_aligned_malloc(padded_size * sizeof(color), 64);
        aligned_colored = (char*)_aligned_malloc(padded_size * sizeof(char), 64);
    #else
        aligned_colors = (color*)aligned_alloc(64, padded_size * sizeof(color));
        aligned_colored = (char*)aligned_alloc(64, padded_size * sizeof(char));
    #endif
    
    // Initialize
    std::fill(aligned_colors, aligned_colors + padded_size, -1);
    std::fill(aligned_colored, aligned_colored + padded_size, 0);
    
    // Use a pointer for easier access
    color* node_colors = aligned_colors;
    char* colored = aligned_colored;
    
    // Calculate average degree for adaptive strategies
    double avg_degree = static_cast<double>(total_neighbors) / node_count;
    std::cout << "Graph density: " << avg_degree << " average degree" << std::endl;
    
    // Configure optimal thread count based on graph properties
    int max_threads = omp_get_max_threads();
    int active_threads;
    
    if (avg_degree > 100) {
        // Dense graph - use fewer threads to reduce contention
        active_threads = std::min(max_threads, 8);
    } else if (avg_degree > 20) {
        // Medium density - balanced approach
        active_threads = std::min(max_threads, 16);
    } else {
        // Sparse graph - use more threads for parallelism
        active_threads = max_threads;
    }
    
    omp_set_num_threads(active_threads);
    std::cout << "Using " << active_threads << " threads (adaptive)" << std::endl;
    
    // Use atomic for global max color
    std::atomic<int> global_max_color{-1};
    
    // Adaptive sequential coloring threshold based on graph density
    size_t seq_threshold;
    if (avg_degree > 50) {
        seq_threshold = std::min(static_cast<size_t>(node_count * 0.3), static_cast<size_t>(5000));
    } else if (avg_degree > 10) {
        seq_threshold = std::min(static_cast<size_t>(node_count * 0.2), static_cast<size_t>(2000));
    } else {
        seq_threshold = std::min(static_cast<size_t>(node_count * 0.1), static_cast<size_t>(1000));
    }
    
    size_t seq_nodes = std::min(seq_threshold, node_count);
    std::cout << "Coloring " << seq_nodes << " highest-degree nodes sequentially..." << std::endl;
    
    // Process high-degree nodes sequentially with optimized color finding
    const size_t BITSET_WORDS = 128;  // Support up to 8192 colors initially
    
    for (size_t i = 0; i < seq_nodes; i++) {
        size_t node_idx = i;
        
        // Use a bitvector for forbidden colors
        uint64_t forbidden_bits[BITSET_WORDS] = {0};
        
        // Mark colors used by neighbors (with optimized bitset operations)
        for (size_t j = neighbor_offsets[node_idx]; j < neighbor_offsets[node_idx + 1]; j++) {
            size_t nb_idx = all_neighbors[j];
            if (colored[nb_idx]) {
                color c = node_colors[nb_idx];
                if (c >= 0) {
                    size_t word_idx = c / 64;
                    size_t bit_idx = c % 64;
                    forbidden_bits[word_idx] |= (1ULL << bit_idx);
                }
            }
        }
        
        // Find first available color (optimized bit operations)
        color selected = 0;
        for (size_t word_idx = 0; word_idx < BITSET_WORDS; word_idx++) {
            uint64_t word = forbidden_bits[word_idx];
            if (word != ~0ULL) {  // Not all bits set
                uint64_t free_bit = ~word & (word + 1);  // Get lowest unset bit
                selected = word_idx * 64 + __builtin_ctzll(free_bit);
                break;
            }
            selected = (word_idx + 1) * 64;
        }
        
        // Assign color
        node_colors[node_idx] = selected;
        colored[node_idx] = 1;
        
        // Update max color with atomic
        int current_max = global_max_color.load(std::memory_order_relaxed);
        while (selected > current_max) {
            if (global_max_color.compare_exchange_weak(current_max, selected, 
                                                     std::memory_order_release,
                                                     std::memory_order_relaxed)) {
                break;
            }
        }
    }
    
    int current_max_color = global_max_color.load(std::memory_order_relaxed);
    std::cout << "Sequential coloring used " << (current_max_color + 1) << " colors" << std::endl;
    
    // Step 2: Process remaining nodes with improved parallel algorithm
    size_t remaining = node_count - seq_nodes;
    std::cout << "Processing remaining " << remaining << " nodes in parallel..." << std::endl;
    
    // Adaptive batch sizing based on graph properties
    size_t batch_size;
    if (avg_degree > 50) {
        batch_size = 256;  // Power of 2 for better memory alignment
    } else if (avg_degree > 10) {
        batch_size = 512;  // Power of 2 for better memory alignment
    } else {
        batch_size = 1024; // Power of 2 for better memory alignment
    }
    
    const size_t num_batches = (remaining + batch_size - 1) / batch_size;
    
    // Improve cache locality with cache-line aligned processing
    const size_t CACHE_LINE_SIZE = 64;
    const size_t NODES_PER_CACHELINE = CACHE_LINE_SIZE / sizeof(color);
    const size_t cache_stride = NODES_PER_CACHELINE * 4; // Avoid false sharing
    
    // Use dynamic scheduling with optimal chunk size for better load balancing
    #pragma omp parallel
    {
        // Per-thread bitset for marking forbidden colors
        const size_t THREAD_BITSET_WORDS = 256;  // Support up to 16384 colors per thread
        std::vector<uint64_t> thread_forbidden(THREAD_BITSET_WORDS, 0);
        int thread_max_color = current_max_color;
        
        #pragma omp for schedule(dynamic, 4)
        for (size_t batch = 0; batch < num_batches; batch++) {
            // Process batches with cache-friendly strides
            for (size_t stride_offset = 0; stride_offset < batch_size; stride_offset += cache_stride) {
                size_t base_idx = seq_nodes + batch * batch_size + stride_offset;
                
                // Process a cache-friendly chunk of nodes
                for (size_t offset = 0; offset < cache_stride && base_idx + offset < node_count; offset++) {
                    size_t node_idx = base_idx + offset;
                    
                    // Skip if already colored
                    if (colored[node_idx]) continue;
                    
                    // Reset forbidden colors (faster than recreating)
                    std::fill(thread_forbidden.begin(), thread_forbidden.end(), 0);
                    
                    // Get neighbors range for this node
                    size_t neighbor_start = neighbor_offsets[node_idx];
                    size_t neighbor_end = neighbor_offsets[node_idx + 1];
                    size_t neighbor_count = neighbor_end - neighbor_start;
                    
                    // Software prefetching for better cache efficiency
                    for (size_t j = 0; j < neighbor_count; j++) {
                        // Prefetch ahead by 16 elements (adjust based on your hardware)
                        if (j + 16 < neighbor_count) {
                            size_t prefetch_idx = all_neighbors[neighbor_start + j + 16];
                            __builtin_prefetch(&node_colors[prefetch_idx], 0, 0);
                            __builtin_prefetch(&colored[prefetch_idx], 0, 0);
                        }
                        
                        size_t nb_idx = all_neighbors[neighbor_start + j];
                        if (colored[nb_idx]) {
                            color c = node_colors[nb_idx];
                            if (c >= 0) {
                                size_t word_idx = c / 64;
                                size_t bit_idx = c % 64;
                                thread_forbidden[word_idx] |= (1ULL << bit_idx);
                            }
                        }
                    }
                    
                    // Find first available color with bit manipulation
                    color selected = 0;
                    for (size_t word_idx = 0; word_idx < THREAD_BITSET_WORDS; word_idx++) {
                        uint64_t word = thread_forbidden[word_idx];
                        if (word != ~0ULL) {  // Not all bits set
                            uint64_t free_bit = ~word & (word + 1);  // Get lowest unset bit
                            selected = word_idx * 64 + __builtin_ctzll(free_bit);
                            break;
                        }
                        selected = (word_idx + 1) * 64;
                    }
                    
                    // Try to apply the color with optimized transaction
                    bool success = false;
                    
                    __transaction_atomic {
                        // Only check immediate neighbors that matter for color conflicts
                        bool conflict = false;
                        for (size_t j = neighbor_start; j < neighbor_end && !conflict; j++) {
                            size_t nb_idx = all_neighbors[j];
                            // Don't use atomic operations inside transaction
                            if (colored[nb_idx] && node_colors[nb_idx] == selected) {
                                conflict = true;
                            }
                        }
                        
                        if (!conflict && !colored[node_idx]) {
                            node_colors[node_idx] = selected;
                            colored[node_idx] = 1;
                            success = true;
                            
                            // Update thread local max
                            if (selected > thread_max_color) {
                                thread_max_color = selected;
                            }
                        }
                    }
                    
                    // If coloring failed, use minimal fast-path transaction with a new color
                    if (!success) {
                        // Get a new color beyond current maximum with atomic increment
                        int new_color = global_max_color.fetch_add(1, std::memory_order_relaxed) + 1;
                        thread_max_color = std::max(thread_max_color, new_color);
                        
                        __transaction_atomic {
                            if (!colored[node_idx]) {
                                node_colors[node_idx] = new_color;
                                colored[node_idx] = 1;
                            }
                        }
                    }
                }
            }
            
            // Periodically update global max color to reduce atomic contention
            if (thread_max_color > global_max_color.load(std::memory_order_relaxed)) {
                int current_max = global_max_color.load(std::memory_order_relaxed);
                while (thread_max_color > current_max) {
                    if (global_max_color.compare_exchange_weak(current_max, thread_max_color,
                                                             std::memory_order_release,
                                                             std::memory_order_relaxed)) {
                        break;
                    }
                }
            }
        }
    }
    
    // Step 3: Conflict detection with SIMD acceleration where possible
    std::vector<size_t> conflict_nodes;
    std::mutex conflict_mutex;
    
    // Divide work into chunks for better cache locality
    const size_t chunk_size = 1024;
    const size_t num_chunks = (node_count + chunk_size - 1) / chunk_size;
    
    #pragma omp parallel for schedule(dynamic, 4)
    for (size_t chunk = 0; chunk < num_chunks; chunk++) {
        size_t start_idx = chunk * chunk_size;
        size_t end_idx = std::min(start_idx + chunk_size, node_count);
        
        std::vector<size_t> local_conflicts;
        
        for (size_t i = start_idx; i < end_idx; i++) {
            bool has_conflict = false;
            
            // Cache color to avoid repeated memory access
            color node_color = node_colors[i];
            
            // Use explicit SIMD directives when supported
            #ifdef __AVX2__
            // Process neighbors in batches of 8 with AVX2
            size_t nb_start = neighbor_offsets[i];
            size_t nb_end = neighbor_offsets[i + 1];
            
            for (size_t j = nb_start; j < nb_end && !has_conflict; j++) {
                size_t nb_idx = all_neighbors[j];
                if (i < nb_idx && node_color == node_colors[nb_idx]) {
                    has_conflict = true;
                }
            }
            #else
            // Use regular vectorization hints for non-AVX2 compilers
            #pragma omp simd reduction(||:has_conflict)
            for (size_t j = neighbor_offsets[i]; j < neighbor_offsets[i + 1]; j++) {
                size_t nb_idx = all_neighbors[j];
                if (i < nb_idx && node_color == node_colors[nb_idx]) {
                    has_conflict = true;
                }
            }
            #endif
            
            if (has_conflict) {
                local_conflicts.push_back(i);
            }
        }
        
        // Batch update conflicts list to reduce lock contention
        if (!local_conflicts.empty()) {
            std::lock_guard<std::mutex> lock(conflict_mutex);
            conflict_nodes.insert(conflict_nodes.end(), local_conflicts.begin(), local_conflicts.end());
        }
    }
    
    if (!conflict_nodes.empty()) {
        std::cout << "Fixing " << conflict_nodes.size() << " color conflicts..." << std::endl;
        
        // Lock-free conflict resolution with atomic global max color
        std::atomic<size_t> conflict_counter{0};
        const size_t conflict_size = conflict_nodes.size();
        
        #pragma omp parallel
        {
            while (true) {
                // Get next conflict to resolve with work stealing
                size_t i = conflict_counter.fetch_add(1, std::memory_order_relaxed);
                if (i >= conflict_size) break;
                
                size_t node_idx = conflict_nodes[i];
                
                // Get a new color beyond current maximum
                int new_color = global_max_color.fetch_add(1, std::memory_order_relaxed) + 1;
                
                // Assign the new color
                __transaction_atomic {
                    node_colors[node_idx] = new_color;
                }
            }
        }
    }
    
    // Final global max color value
    int final_max_color = global_max_color.load(std::memory_order_relaxed);
    
    // Copy to output map with parallel processing for large graphs
    if (node_count > 10000) {
        // Parallel copy with chunking to reduce contention
        const size_t copy_chunk = 1024;
        const size_t copy_chunks = (node_count + copy_chunk - 1) / copy_chunk;
        
        #pragma omp parallel
        {
            #pragma omp for schedule(dynamic, 1)
            for (size_t chunk = 0; chunk < copy_chunks; chunk++) {
                size_t start = chunk * copy_chunk;
                size_t end = std::min(start + copy_chunk, node_count);
                
                std::unordered_map<graphNode, color> local_colors;
                local_colors.reserve(end - start);
                
                for (size_t i = start; i < end; i++) {
                    local_colors[ordered_nodes[i]] = node_colors[i];
                }
                
                #pragma omp critical
                {
                    colors.insert(local_colors.begin(), local_colors.end());
                }
            }
        }
    } else {
        // Direct copy for smaller graphs
        for (size_t i = 0; i < node_count; i++) {
            colors[ordered_nodes[i]] = node_colors[i];
        }
    }
    
    // Final validation with optimized approach
    bool valid_coloring = true;
    std::atomic<size_t> conflict_count{0};
    
    #pragma omp parallel for schedule(dynamic, 1024) reduction(&&:valid_coloring)
    for (size_t i = 0; i < node_count; i++) {
        bool local_valid = true;
        int local_conflicts = 0;
        
        for (size_t j = neighbor_offsets[i]; j < neighbor_offsets[i + 1]; j++) {
            size_t nb_idx = all_neighbors[j];
            if (i < nb_idx && node_colors[i] == node_colors[nb_idx]) {
                local_valid = false;
                local_conflicts++;
            }
        }
        
        if (!local_valid) {
            valid_coloring = false;
            conflict_count.fetch_add(local_conflicts, std::memory_order_relaxed);
        }
    }
    
    // Free aligned memory
    #ifdef _MSC_VER
        _aligned_free(aligned_colors);
        _aligned_free(aligned_colored);
    #else
        free(aligned_colors);
        free(aligned_colored);
    #endif
    
    // End timer and report performance
    double end_time = omp_get_wtime();
    double time_spent = end_time - start_time;
    
    std::cout << "Time spent: " << time_spent << std::endl;
    std::cout << "Colored with " << (final_max_color + 1) << " colors" << std::endl;
    
    if (!valid_coloring) {
        std::cout << "Failed to color graph correctly. " << conflict_count.load() << " conflicts detected." << std::endl;
    } else {
        std::cout << "Coloring validation successful." << std::endl;
    }
}



// Factory function
std::unique_ptr<ColorGraph> createSTMColorGraph(const char* stm_type, int iterations, bool try_bipartite) {
    static bool registered = false;
    if (!registered) {
        std::atexit(cleanupThreadLocalStorage);
        registered = true;
    }
    
    if (strcmp(stm_type, "tl2") == 0) {
            return std::unique_ptr<ColorGraph>(new TL2ColorGraph(iterations, try_bipartite));
    } else {
            return std::unique_ptr<ColorGraph>(new LibITMColorGraph(iterations, try_bipartite));
        }
}